<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# Reinforcement Learning (RL) with Simulate

Simulate is designed to provide easy and scalable integration with reinforcement learning algorithms.
The core abstraction is through the [`RLEnv`] class that wraps a [`Scene`].
The [`RLEnv`] allows an [`Actuator`] to be manipulated by an external agent or policy.

It is core to the design of Simulate that we are *not creating* Agents, but rather providing an interface for applications of machine learning and embodied AI.
The core API for RL applications can be seen below, where Simulate constrains the information that flows from the Scene to the external agent through an Actuator abstraction.

<p align="center">
    <br>
    <img src="..assets/rl.png" width="500"/>
    <br>
</p>

At release, we include a set of pre-designed `Actor`'s that can act or navigate a scene. An `Actor` inherits from an `Object3D` and has sensors, actuators, and action mappings.


## Core Classes

### Actuator
[[autodoc]] Actuator

### RLEnv
[[autodoc]] RLEnv

### ActionMapping
[[autodoc]] ActionMapping

## Included Actors

[[autodoc]] SimpleActor

[[autodoc]] EgocentricCameraActor

## Future Applications
In the future we intend to support more functionality such as multi-agent RL, accelerated physics, and more.
